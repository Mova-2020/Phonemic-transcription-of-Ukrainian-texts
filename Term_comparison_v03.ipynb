{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzBKGLZnKNJ4/Xi4RgZb6a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mova-2020/Phonemic-transcription-of-Ukrainian-texts/blob/main/Term_comparison_v03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Pn3BQvsXLt3",
        "outputId": "3106ce89-0072-4c25-b21e-5da5edc20c6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.3.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.27.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "JDxls0NdXTSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('all-mpnet-base-v2')\n",
        "# Load a pre-trained sentence transformer model"
      ],
      "metadata": {
        "id": "OvWF31wBXgIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper functions for each criterion"
      ],
      "metadata": {
        "id": "-Ogx5r1nLy_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Exactness (cosine similarity between term and definition embeddings)\n",
        "def exactness(term_embedding, definition_embedding):\n",
        "    return cosine_similarity([term_embedding], [definition_embedding])[0][0]"
      ],
      "metadata": {
        "id": "rNTk9_I2L3dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Essentiality (ratio of largest and second-largest entailment degrees from definition)\n",
        "def essentiality(entailments):\n",
        "    largest = max(entailments)\n",
        "    second_largest = sorted(entailments, reverse=True)[1]\n",
        "    return largest / second_largest if second_largest != 0 else float('inf')"
      ],
      "metadata": {
        "id": "AqNL1gJGMLy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Plainness (ratio of subwords in term and definition)\n",
        "def plainness(term, definition):\n",
        "    term_subwords = set(term.split())\n",
        "    definition_subwords = set(definition.split())\n",
        "    common_subwords = term_subwords.intersection(definition_subwords)\n",
        "    return len(common_subwords) / len(term_subwords) if term_subwords else 0"
      ],
      "metadata": {
        "id": "iahk1ljrMNGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Derivativity (Checking for specific endings and addable subwords)\n",
        "def derivativity(term):\n",
        "    if term.endswith((\"nnja\", \"tja\", \"ння\", \"тя\")):\n",
        "        return 0  # Bad derivation if ending in \"nnja\" or \"ttja\"\n",
        "    else:\n",
        "        return 1  # Can add subwords (placeholder, needs more logic)"
      ],
      "metadata": {
        "id": "T4J6QTOzMaWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Good sound phonotactic rule compliance)\n",
        "def good_sound(term):\n",
        "    bad_clusters = [\"ngh\", \"shr\", \"zhr\", \"нг\", \"шр\", \"жр\"]\n",
        "    if any(cluster in term for cluster in bad_clusters):\n",
        "        return 0\n",
        "    return 1  # No bad clusters"
      ],
      "metadata": {
        "id": "5VplE1ZzMet8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Systemic feature (Existence of meronyms or hypernyms in the dictionary)\n",
        "def systemic_feature(term, dictionary_entries):\n",
        "    related_entries = [entry for entry in dictionary_entries if term in entry]\n",
        "    return len(related_entries)"
      ],
      "metadata": {
        "id": "DJruXvMyMkH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Organicity (Inverse of maximum subword length)\n",
        "def organicity(term):\n",
        "    subwords = term.split()\n",
        "    max_length = max(len(subword) for subword in subwords)\n",
        "    return 1 / max_length if max_length != 0 else 0"
      ],
      "metadata": {
        "id": "_khWN1OnMoC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Compatibility (Valence of the term or closest analogs)\n",
        "def compatibility(term, term_valences):\n",
        "    return term_valences.get(term, 0)  # Placeholder for valence calculation"
      ],
      "metadata": {
        "id": "MKk5cZCeMq4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Unambiguity (Inverse of number of definitions for the term)\n",
        "def unambiguity(definitions_count):\n",
        "    return 1 / definitions_count if definitions_count != 0 else 0"
      ],
      "metadata": {
        "id": "Kg-iZwCKMwM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Nominativity (Formula-based calculation)\n",
        "def nominativity(conjunctions, verb_endings):\n",
        "    nconj = len(conjunctions)\n",
        "    nend = len([ending for ending in verb_endings if ending in [\"ty\", \"tysja\", \"tysj\", \"ти\", \"тися\", \"тись\"]])\n",
        "    return 1 / (1 + nconj + nend)"
      ],
      "metadata": {
        "id": "NDXcCHmjM3rW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Brevity (Inverse number of symbols in the term)\n",
        "def brevity(term):\n",
        "    return 1 / len(term) if len(term) != 0 else 0"
      ],
      "metadata": {
        "id": "5ghLkaQcM4cF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data input"
      ],
      "metadata": {
        "id": "a8bv88_zNOln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_terms_from_user():\n",
        "    # Просить користувача ввести терміни та їх означення для порівняння\n",
        "    while True:\n",
        "        try:\n",
        "            num_terms_input = input(\"Введіть кількість термінів для порівняння (за замовчуванням 2): \")\n",
        "            num_terms = int(num_terms_input) if num_terms_input else 2  # Use 2 as default if input is empty\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"Неправильний ввід. Будь ласка, введіть число.\")\n",
        "\n",
        "    terms_and_definitions = {}  # Using a dictionary to store terms and definitions\n",
        "    for i in range(num_terms):\n",
        "        term = input(f\"Введіть термін {i + 1}: \")\n",
        "        definition = input(f\"Введіть означення для терміна '{term}': \")\n",
        "        terms_and_definitions[term] = definition  # Store term and definition in the dictionary\n",
        "    return terms_and_definitions  # Return the dictionary\n"
      ],
      "metadata": {
        "id": "YzXlt7b0NSNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scores"
      ],
      "metadata": {
        "id": "mkn_oA8123Kb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_scores_for_terms(terms_and_definitions):\n",
        "    # Обчислює бали для кожного терміна\n",
        "    # Replace with your actual dictionary of terms.\n",
        "    dictionary = {\"термін1\": \"означення1\", \"термін2\": \"означення2\"}\n",
        "\n",
        "    # Replace with your actual valence data for terms.\n",
        "    term_valences = {\"термін1\": 2, \"термін2\": 1}\n",
        "\n",
        "    scores = {}\n",
        "    for term, definition in terms_and_definitions.items():\n",
        "        # Generate embeddings for term and definition\n",
        "        term_embedding = model.encode(term)\n",
        "        definition_embedding = model.encode(definition)\n",
        "\n",
        "        # Calculate Exactness using cosine similarity\n",
        "        exactness_score = cosine_similarity([term_embedding], [definition_embedding])[0][0]\n",
        "        print(f\"Cosine similarity for '{term}': {exactness_score}\") # Print for debugging\n",
        "\n",
        "        # Essentiality Calculation (placeholder - requires entailment logic)\n",
        "        # Replace this with your actual entailment calculation\n",
        "        entailments = [0.8, 0.6, 0.4]  # Example entailment degrees\n",
        "        essentiality_score = essentiality(entailments)\n",
        "\n",
        "\n",
        "        # Plainness calculation (using sets for intersection)\n",
        "        term_subwords = set(term.lower().split())\n",
        "        definition_subwords = set(definition.lower().split())\n",
        "        common_subwords = term_subwords.intersection(definition_subwords)\n",
        "        plainness_score = len(common_subwords) / len(term_subwords) if term_subwords else 0\n",
        "        print(f\"Common subwords for '{term}': {common_subwords}\")  # Print for debugging\n",
        "\n",
        "        # Initialize scores for the current term\n",
        "        scores_term = {\n",
        "            \"Exactness\": exactness_score,\n",
        "            \"Essentiality\": essentiality_score,\n",
        "            \"Plainness\": plainness_score,\n",
        "            \"Derivativity\": derivativity(term),\n",
        "            \"Good Sound\": good_sound(term),\n",
        "            # Use the populated dictionary\n",
        "            \"Systemic Feature\": systemic_feature(term, list(dictionary.keys())),\n",
        "            \"Organicity\": organicity(term),\n",
        "            # Use the populated term_valences\n",
        "            \"Compatibility\": compatibility(term, term_valences),\n",
        "            \"Unambiguity\": 1,  # Replace with actual calculation based on definition count\n",
        "            \"Nominativity\": nominativity([], []),  # No conjunctions or verb endings in the term\n",
        "            \"Brevity\": brevity(term),\n",
        "        }\n",
        "        scores[term] = scores_term\n",
        "        #Assign scores_term to scores dictionary with term as key\n",
        "    return scores\n"
      ],
      "metadata": {
        "id": "osU3_-DU24-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison"
      ],
      "metadata": {
        "id": "PHH2bIZIOuK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "terms_and_definitions = get_terms_from_user()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3ULQw7PTFDG",
        "outputId": "4ec2b616-1573-4cdf-c8e2-ddeb18691757"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Введіть кількість термінів для порівняння (за замовчуванням 2): \n",
            "Введіть термін 1: вага статистична\n",
            "Введіть означення для терміна 'вага статистична': Число різних квантових станів з даною енергією. У випадку неперервного розподілу енергії – кількість станів у даному інтервалі значень енергії.\n",
            "Введіть термін 2: кратність стану\n",
            "Введіть означення для терміна 'кратність стану': Число різних квантових станів з даною енергією. У випадку неперервного розподілу енергії – кількість станів у даному інтервалі значень енергії.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = calculate_scores_for_terms(terms_and_definitions)\n",
        "#Call the calculate_scores_for_terms function to get the scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNyKRIK8TMP9",
        "outputId": "9c91091f-4b02-4de0-e7d0-c0c0a4e3ce1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity for 'вага статистична': 0.5460278987884521\n",
            "Common subwords for 'вага статистична': set()\n",
            "Cosine similarity for 'кратність стану': 0.6928146481513977\n",
            "Common subwords for 'кратність стану': set()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for term, term_scores in scores.items():\n",
        "    print(f\"Бали для терміна '{term}': {term_scores}\")\n",
        "    overall_score = sum(term_scores.values()) / len(term_scores)\n",
        "    print(f\"Загальний бал для терміна '{term}': {overall_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNiom6TDOu1U",
        "outputId": "457e4ece-f6cd-4fe4-c548-ba97d02ff197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Бали для терміна 'вага статистична': {'Exactness': 0.5460279, 'Essentiality': 1.3333333333333335, 'Plainness': 0.0, 'Derivativity': 1, 'Good Sound': 1, 'Systemic Feature': 0, 'Organicity': 0.09090909090909091, 'Compatibility': 0, 'Unambiguity': 1, 'Nominativity': 1.0, 'Brevity': 0.0625}\n",
            "Загальний бал для терміна 'вага статистична': 0.5484336657300797\n",
            "Бали для терміна 'кратність стану': {'Exactness': 0.69281465, 'Essentiality': 1.3333333333333335, 'Plainness': 0.0, 'Derivativity': 1, 'Good Sound': 1, 'Systemic Feature': 0, 'Organicity': 0.1111111111111111, 'Compatibility': 0, 'Unambiguity': 1, 'Nominativity': 1.0, 'Brevity': 0.06666666666666667}\n",
            "Загальний бал для терміна 'кратність стану': 0.5639932508420462\n"
          ]
        }
      ]
    }
  ]
}